{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327727fe",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bc1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os, sys\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pytorch_lightning as pl\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import functional as Func\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.dirname(os.path.realpath('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219e2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.supernet import SuperNet\n",
    "from helpers.gradcam import NetworkGradCAM\n",
    "from helpers.xrai import XRai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16086436",
   "metadata": {},
   "source": [
    "# Data Read-Ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a53027",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH = '/home/jmryan/teams/dsc-180a---a14-[88137]/bnpp_224_pandas/'\n",
    "TEST_PATH = '/home/jmryan/private/DSC180/A/test/testdata.csv'\n",
    "TRAIN_PATH = '/home/jmryan/private/DSC180/A/train/traindata.csv'\n",
    "VAL_PATH = '/home/jmryan/private/DSC180/A/val/valdata.csv'\n",
    "SEG_PATH = '/home/jmryan/teams/dsc-180a---a14-[88137]/segmented_datapaths_meta.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "774db38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_PATH, header=0, index_col=0)\n",
    "train = pd.read_csv(TRAIN_PATH, index_col = 0)\n",
    "val = pd.read_csv(VAL_PATH, index_col = 0)\n",
    "seg = pd.read_csv(SEG_PATH, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28f62792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prop Train W Segments: 0.8810999736217356\n",
      "Prop Val W Segments: 0.8687924725561944\n",
      "Prop Test W Segments: 0.8754799780581459\n"
     ]
    }
   ],
   "source": [
    "print(f'Prop Train W Segments: {len(train.merge(seg))/len(train)}')\n",
    "print(f'Prop Val W Segments: {len(val.merge(seg))/len(val)}')\n",
    "print(f'Prop Test W Segments: {len(test.merge(seg))/len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd5d36",
   "metadata": {},
   "source": [
    "- once mimic data available, preprocessed needs to just be filepath and binary value so it works w both\n",
    "    -means need another class/func before for albert data to mess w bnpp threshold for binary truth\n",
    "        -make sure to keep results from different thresholds for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c24daa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessedImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, target_transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df[idx]\n",
    "        filepath = row[2]  \n",
    "        val = row[0]\n",
    "        heart = row[1]\n",
    "        im = torch.load(DATA_DIR_PATH + filepath)\n",
    "        return im.view(1, 224, 224).expand(3, -1, -1), val, heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33429cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PreprocessedImageDataset(df=train_df.to_numpy())\n",
    "val_dataset = PreprocessedImageDataset(df=val_df.to_numpy())\n",
    "test_dataset = PreprocessedImageDataset(df=test_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3973578",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=16, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers = 16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792bae5f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bbb325b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb66966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet152(weights=ResNet152_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7955b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lin = [[2048, 4096], [4096, 2048], [2048, 512], [512, 256], [256, 1]]\n",
    "\n",
    "net = SuperNet(layer_defs=None, linear_layers = final_lin, is_transfer=True, \n",
    "           model = model, lr_scheduler=True, lr = 1e-5, print_on = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f502f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
