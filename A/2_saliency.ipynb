{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641b6daf",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c429cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!alias python==python3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21977df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 588.3 MB 33 kB/s s eta 0:00:01   |█▍                              | 25.3 MB 8.4 MB/s eta 0:01:07     |██                              | 37.4 MB 8.4 MB/s eta 0:01:06��███▊                        | 142.7 MB 28.3 MB/s eta 0:00:16     |██████████████                  | 255.7 MB 55.7 MB/s eta 0:00:06     |█████████████████               | 314.3 MB 46.0 MB/s eta 0:00:06�███████████████▎           | 373.8 MB 59.0 MB/s eta 0:00:04�███████████        | 440.6 MB 49.5 MB/s eta 0:00:03 eta 0:00:03MB/s eta 0:00:03��█████████████████████████   | 534.7 MB 83.0 MB/s eta 0:00:01�██ | 569.9 MB 50.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[K     |████████████████████████████████| 439 kB 34.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorflow) (1.51.1)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 39.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.17.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 36.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 48.6 MB/s eta 0:00:01�████▊                     | 5.8 MB 48.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.5 MB 39.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jmryan/.local/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jmryan/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jmryan/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jmryan/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jmryan/.local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/jmryan/.local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/jmryan/.local/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Installing collected packages: numpy, tensorflow-io-gcs-filesystem, tensorflow-estimator, libclang, keras, flatbuffers, tensorflow\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.9 are installed in '/home/jmryan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/jmryan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.6.0 requires absl-py~=0.10, but you have absl-py 1.4.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 23.1.21 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires h5py~=3.1.0, but you have h5py 3.3.0 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.24.2 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.3.0 which is incompatible.\n",
      "scipy 1.7.0 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.2 which is incompatible.\u001b[0m\n",
      "Successfully installed flatbuffers-23.1.21 keras-2.11.0 libclang-15.0.6.1 numpy-1.24.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdda9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: tensorflow\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "227d1efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.5\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7cf778f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.3.0 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow==2.3.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tensorflow==2.3.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6841050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: tensorflow\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "680d2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os, time, sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pytorch_lightning as pl\n",
    "import h5py\n",
    "sys.path.append(os.path.dirname(os.path.realpath('.')))\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import functional as Func\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_score, roc_curve, confusion_matrix\n",
    "import glob\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "pio.renderers.default = 'svg'\n",
    "pio.templates.default = 'plotly_white'\n",
    "import cv2\n",
    "from helpers.lightning_interface import *\n",
    "from helpers.supernet import *\n",
    "from helpers.xrai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca88416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.gradcam import NetworkGradCAM\n",
    "import matplotlib as mpl\n",
    "from skimage.transform import resize\n",
    "import saliency.core as saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8595a47",
   "metadata": {},
   "source": [
    "# Data Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa261b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH = '/home/jmryan/teams/dsc-180a---a14-[88137]/bnpp_224_pandas/'\n",
    "TEST_PATH = '/home/jmryan/private/DSC180/A/test/testdata.csv'\n",
    "TRAIN_PATH = '/home/jmryan/private/DSC180/A/train/traindata.csv'\n",
    "VAL_PATH = '/home/jmryan/private/DSC180/A/val/valdata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa78b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH, index_col=0)\n",
    "val_df = pd.read_csv(VAL_PATH, index_col=0)\n",
    "test_df = pd.read_csv(TEST_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2ab99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessedImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, target_transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df[idx]\n",
    "        filepath = row[2]  \n",
    "        val = row[0]\n",
    "        heart = row[1]\n",
    "        im = torch.load(DATA_DIR_PATH + filepath)\n",
    "        return im.view(1, 224, 224).expand(3, -1, -1), val, heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c355ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PreprocessedImageDataset(df=train_df.to_numpy())\n",
    "val_dataset = PreprocessedImageDataset(df=val_df.to_numpy())\n",
    "test_dataset = PreprocessedImageDataset(df=test_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd1446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=16, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers = 16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f22ea3",
   "metadata": {},
   "source": [
    "# Model Load In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1e91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet152(weights=ResNet152_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7338018",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lin = [[2048, 4096], [4096, 2048], [2048, 512], [512, 256], [256, 1]]\n",
    "net = SuperNet(layer_defs=None, linear_layers = final_lin, is_transfer=True, \n",
    "           model = model, lr_scheduler=True, lr = 1e-5, print_on = False)\n",
    "net.load_state_dict(torch.load('presentation_figs/final_model'))\n",
    "net.to('cuda');\n",
    "net.turn_grad(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e079d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cf77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model_function(images, call_model_args=None, expected_keys=None):\n",
    "    images = torch.movedim(torch.tensor(images), 3, 1).requires_grad_(True)\n",
    "#     print(images.shape)\n",
    "    \n",
    "#     target_regression =  call_model_args[class_idx_str] ### NOT SURE\n",
    "    \n",
    "    outputs = net(images.to('cuda')).to('cpu')\n",
    "    \n",
    "    if saliency.base.INPUT_OUTPUT_GRADIENTS in expected_keys:\n",
    "        grads = torch.autograd.grad(outputs, images, grad_outputs=torch.ones_like(outputs))\n",
    "        grads = torch.movedim(grads[0], 1, 3)\n",
    "        gradients = grads.detach().numpy()\n",
    "        return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebedf749",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in val_dl:\n",
    "    break\n",
    "images= i[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b220b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22df2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "XRai = XRai(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4d66eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06757358, 0.06757358, 0.06757358, ..., 0.12449619, 0.12449619,\n",
       "        0.01830193],\n",
       "       [0.06757358, 0.06757358, 0.06757358, ..., 0.12449619, 0.12449619,\n",
       "        0.12449619],\n",
       "       [0.06757358, 0.06757358, 0.06757358, ..., 0.12449619, 0.12449619,\n",
       "        0.12449619],\n",
       "       ...,\n",
       "       [0.06485655, 0.06485655, 0.06485655, ..., 0.10369667, 0.10369667,\n",
       "        0.03834481],\n",
       "       [0.06485655, 0.06485655, 0.06485655, ..., 0.10369667, 0.10369667,\n",
       "        0.03834481],\n",
       "       [0.06485655, 0.06485655, 0.06485655, ..., 0.10369667, 0.10369667,\n",
       "        0.03834481]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XRai(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5446c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87624fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(images.to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.movedim(images, 1, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e34574",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = call_model_function(torch.movedim(images, 1, 3).numpy(), expected_keys = ['INPUT_OUTPUT_GRADIENTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6db8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['INPUT_OUTPUT_GRADIENTS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['INPUT_OUTPUT_GRADIENTS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce7b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrai_object = saliency.XRAI()\n",
    "\n",
    "# Compute XRAI attributions with default parameters\n",
    "xrai_attributions = xrai_object.GetMask(torch.movedim(images, 0, 2).numpy(), \n",
    "                                        call_model_function, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate methods.\n",
    "def ShowImage(im, title='', ax=None):\n",
    "    if ax is None:\n",
    "        P.figure()\n",
    "    P.axis('off')\n",
    "    P.imshow(im)\n",
    "    P.title(title)\n",
    "\n",
    "def ShowGrayscaleImage(im, title='', ax=None):\n",
    "    if ax is None:\n",
    "        P.figure()\n",
    "    P.axis('off')\n",
    "    P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n",
    "    P.title(title)\n",
    "\n",
    "def ShowHeatMap(im, title, ax=None):\n",
    "    if ax is None:\n",
    "        P.figure()\n",
    "    P.axis('off')\n",
    "    P.imshow(im, cmap='inferno')\n",
    "    P.title(title)\n",
    "\n",
    "def LoadImage(file_path):\n",
    "    im = PIL.Image.open(file_path)\n",
    "    im = im.resize((299, 299))\n",
    "    im = np.asarray(im)\n",
    "    return im\n",
    "\n",
    "transformer = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "def PreprocessImages(images):\n",
    "    # assumes input is 4-D, with range [0,255]\n",
    "    #\n",
    "    # torchvision have color channel as first dimension\n",
    "    # with normalization relative to mean/std of ImageNet:\n",
    "    #    https://pytorch.org/vision/stable/models.html\n",
    "    images = np.array(images)\n",
    "    images = images/255\n",
    "    images = np.transpose(images, (0,3,1,2))\n",
    "    images = torch.tensor(images, dtype=torch.float32)\n",
    "    images = transformer.forward(images)\n",
    "    return images.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate imports.\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from matplotlib import pylab as P\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# From our repository.\n",
    "import saliency.core as saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86035dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = torch.movedim(images, 0, 2).numpy()\n",
    "ROWS = 1\n",
    "COLS = 3\n",
    "UPSCALE_FACTOR = 20\n",
    "P.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "\n",
    "# Show original image\n",
    "ShowImage(im, title='Original Image', ax=P.subplot(ROWS, COLS, 1))\n",
    "\n",
    "# Show XRAI heatmap attributions\n",
    "ShowHeatMap(xrai_attributions, title='XRAI Heatmap', ax=P.subplot(ROWS, COLS, 2))\n",
    "\n",
    "# Show most salient 30% of the image\n",
    "mask = xrai_attributions >= np.percentile(xrai_attributions, 70)\n",
    "im_mask = np.array(im)\n",
    "im_mask[~mask] = 0\n",
    "ShowImage(im_mask, title='Top 30%', ax=P.subplot(ROWS, COLS, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587cbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value = i[0][0]\n",
    "x_baseline = [baselines[0]]\n",
    "x_steps = 25\n",
    "x_diff = x_value - x_baseline[0]\n",
    "\n",
    "total_gradients = np.zeros_like(x_value, dtype=np.float32)\n",
    "\n",
    "x_step_batched = []\n",
    "for alpha in np.linspace(0, 1, x_steps):\n",
    "    x_step = x_baseline + alpha * x_diff\n",
    "    x_step_batched.append(x_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['INPUT_OUTPUT_GRADIENTS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.backward(retain_graph=True)\n",
    "grads = gCAM.get_activations_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f752be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.turn_grad(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "gCAM = NetworkGradCAM(net)\n",
    "\n",
    "# set evaluation mode\n",
    "gCAM.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35df42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
